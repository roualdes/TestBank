# TestBank

To perform a quick test of the features, clone this repository and
`cd` into the directory. Then run TestBank with

```
$ npm install
$ python3 main.py
```

and then in a separate window run

```
$ curl http://localhost:3000/ID
```

where `ID` can be any exercise ID found in db.json.

## Examples

The directory `examples` contains two primary examples. First, an
approximate exam from my MATH 314 course at [Chico
State](https://www.csuchico.edu/). The second a working example of how
one could leverage TestBank with
[check50](https://cs50.readthedocs.io/check50/). Each subfolder has
its own README.

## Data

For now, let's simplify things and store exercises in .json files. I'll use
[lowdb](https://github.com/typicode/lowdb) to interact with the JSON
files. There will be one file for exercises and one file for tags.
The last bit will be how each exercise is returned to the end user.

### Exercise schema

```
{
    id: "a unique ID, 4 characters long; [0-9a-zA-Z]{4}", # generated by TestBank
    language: python | r,
    exercise: "code to produce an exercise",
    tags: ["tag1", ..., "tagT"] # planned but not implemented,
}
```

### Tags

If a user searches the database with a complex query such as `tags: tag1 AND (tag2 OR tag3)`, then the following secondary database should
make for more efficient searching.

```
{
    tag1: [id1, ..., idA],
    tag2: [id1, ..., idB],
    ...
    tagT: [id1, ..., idT]
}
```

After collecting the queried tags' arrays, simple set operations
should enable direct replacement of AND with `&&` and OR with `||`.

### Output schema

TODO provide descriptions of each part of the schemas.

Each exercise will be returned from the TestBank server as a JSON
object with one of the two following structures. If an exercise
is requested, the user will receive a JSON object with the following schema

```
{
    id: "a unique ID, 4 characters long; [0-9a-zA-Z]{4}",
    seed: 1234,
    context: "the context of this exercise",
    questions: ["partA", ..., "partZ"],
    random: {X: x, μ: m, σ: s} # Associative Array specific to language
    # eg R => list(), Python => dict() or {}
}
```

If a solution is requested, the user will receive a JSON object with
the following schema

```
{
  seed: 1234,
  id: "a unique ID, 4 characters long; [0-9a-zA-Z]{4}",
  solution: ["partA", ..., "partZ"],
  random: {X: x, μ: m, σ: s} # Associative Array specific to language
  # eg R => list(), Python => dict() or {}
}
```

There should be some sort of authorization to request a solution set.

## Writing exercises

To write an exercise, you must at least use the following structure,
inclusive of the custom [Mustache](https://github.com/janl/mustache.js) tags
for the exercise's ID:

```
id = '#< ID >#'
... code to produce Output schema
```

These custom Mustache tags have two benefits. First, they help
prevent my text editor from getting confused while developing TestBank
exercises, at least within some fairly standard data science
programming languages, R, Python, Julia. Second, they simplify writing LaTeX
within Python strings, since Python's string formatting insists on
double curly braces (otherwise used in Mustache) to get single curly
braces (used in LaTeX) into a string.

Examples exist in the
[examples](https://github.com/roualdes/testbank/tree/master/examples)
directory.

### Extra Mustache tags

If you want to provide a seed and/or solutions, and keep the solution
hidden from the website, use Mustache tags that allow TestBank to
selectively ignore the exercise and/or the solution.

```
... code necessary for both exercise and solution
id = '#< ID >#'
seeed = #< SEED >#

#< #exercise >#
... code to produce exercise Output schema
#< /exercise >#

#< #solution >#
... code to produce solution Output schema
#< /solution >#
```

If you want to ignore the seed altogether, the JSON file containing
the exercises meta data should contain an appropriate null value for
the language the exercise is written in. See
[examples/ex04.r](https://github.com/roualdes/testbank/tree/master/examples)
as an example.

More examples exist in the [examples/
directory](https://github.com/roualdes/testbank/tree/master/examples).

## Checking an exercise before entering it into the database

The goal is to make entering exercises into the database as automatic
as possible, while simultaneously addressing _security_ of the TestBank
sever, _stability_ of the kernel, and _response_ time.

### Steps

1. Eyeball code for malicious content.
2. Esnure run time is approximately less 2 seconds by
   testing the exercise, see TestBank CLI below. For instance, could
   run something like
   `time node cli.js test examples/ex01.json | python`
3. Run TestBank's CLI command `upsert`, see TestBank CLI below.

## TestBank command line interface (CLI)

TestBank's GitHub repository comes with a command line interface,
`cli.js`, which attempts to help with testing exercises/solutions and
entering exercises/solutions into the database. The `node` commands
below must be run from the root directory of this repository.

### Testing

To test whether or not an exercise will run (after the Mustache tags
are entered), consider the file
[examples/ex03.r](https://github.com/roualdes/testbank/tree/master/examples/ex03.r).
At the command line, with
[littler](http://dirk.eddelbuettel.com/code/littler.html)
installed/aliased as `lr` run

```
$ lr -e "$(node cli.js test examples/ex03.json exercise)"
```

If the above command runs just fine, then there's a hope that your
code will run on the TestBank kernel after being entered into the
TestBank database.

To test a Python solution, run

```
$ node cli.js test examples/ex01.json solution | python
```

### Inserting an exercise into TestBanks's database

To insert an exercise into TestBank's database, use the command line
interface as

```
$ node cli.js insert ex.json
```

Where `ex.json` is JSON file for an exercise which provides some meta
information about the exercise to be entered. See examples in the
[examples/
directory](https://github.com/roualdes/testbank/tree/master/examples)
for more information.

## TODO

[] An example with code embedded in the exercise. This is likely to
get ugly.

[] Authorization for requested solutions, which, to me, implies that
exercises and their solutions are requested separately. Hmm, what of
the seed then?

[] Figure out versions of dependencies.

[] Develop a database searchable landing/home page for TestBank.

[] Insert (possible) FAQs as exercises in the database. Should double
as helping to explain how to use TestBank and show off some of the
features, like showing/hiding solutions and leaving null the SEED.

[] GZIP databases.

## Dependencies

To successfully run all of the examples, one needs

- [Node.js](https://nodejs.org/),
- [Python3](https://www.python.org/),
- [R](https://www.r-project.org/),

and the following packages within each language's ecosystem

- Use [pip](https://pip.pypa.io/en/stable/) to obtain
  - [jupyterlab](https://jupyterlab.readthedocs.io/en/stable/)
  - [numpy](https://www.numpy.org/)
  - [scipy](https://www.scipy.org/)
  - [pandas](https://pandas.pydata.org/)
- Use R's function `install.packages()` to obtain
  - [IRkernel](https://github.com/IRkernel/IRkernel)
    - After installation, in R (not RStudio), within a Terminal that
      has access to the Python envirnoment containing jupyterlab, run
      ```
      library(IRkernel)
      IRkernel::installspec()
      ```
  - [dplyr](https://dplyr.tidyverse.org/)
  - [tidyverse](https://ggplot2.tidyverse.org/)
  - [jsonlite](https://cran.r-project.org/web/packages/jsonlite/index.html)
  - [pander](https://rapporter.github.io/pander/)
  - [littler](http://dirk.eddelbuettel.com/code/littler.html)

This is my best attempt at a complete list, but I'm still iffy about
versions of everything. Let me know what I've missed.

## License

License: Open source, [BSD (3-clause)](https://opensource.org/licenses/BSD-3-Clause).
